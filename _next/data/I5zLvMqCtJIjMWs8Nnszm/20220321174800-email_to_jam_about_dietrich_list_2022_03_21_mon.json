{"pageProps":{"title":"email to jam about dietrich-list [2022-03-21 Mon]","hast":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dear Jam,\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I hope the past 20 days have been good to you. How've you been?\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Vipassana went well, and they did indeed feed me enough. (At any rate it was enough not to feel hungry or faint. The day does involve a lot of sitting still.)\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Here is what happened in the past week, and in part in my brain in the ten days preceding:\n"}]},{"type":"element","tagName":"h1","properties":{"id":"misunderstanding-and-resolution"},"children":[{"type":"text","value":"misunderstanding and resolution"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I realized I'd misundestood part of the Dietrich-List paper: I'd taken the alphabet of properties as constituting outcomes, but DL constructs them in the reverse way, saying that alternatives/outcomes constitute properties. This is much nicer for treating properties as a structure-preserving \"intermediate representation\" when going from motivational states to outcomes or vice versa.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"It also solves \"for free\" the issue I was facing in building a player's preferences over alternatives from their preferences over properties: I was assuming that preferences over properties would be acyclic, but this is the exact assumption the paper is trying to dispense with :facepalm:\n"}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I reread the axiomatization to be sure I understood it correctly this time, and wrote a note and a distinguishing scenario:\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  The model discussed by this paper is one where the outcomes of a game each have various properties; and player preferences operate over these properties, rather than the outcomes themselves.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  In addition, players filter their preferences on the basis of which properties they may consider relevant. That set of relevant properties is called a player's motivational state. Each player has a set of possible motivational states.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  Two axiom systems are presented: 1+2, and 1+3.\n"}]},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"motivational states that contain no properties that discriminate between two outcomes do not generate preferences that distinguish between the outcomes.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"for motivational states "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"A,B, A \\subset B"}]},{"type":"text","value":", if "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"B/A"}]},{"type":"text","value":" contains no properties that are present in two outcomes, then "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"B"}]},{"type":"text","value":" and "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"A"}]},{"type":"text","value":" agree with respect to those outcomes.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"for motivational states "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"A,B, A \\subset B"}]},{"type":"text","value":", if "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"B/A"}]},{"type":"text","value":" contains no properties that discriminate between two outcomes, then "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"B"}]},{"type":"text","value":" and "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"A"}]},{"type":"text","value":" agree with respect to those outcomes.\n"}]}]}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  A scenario that distinguishes the systems:\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  Suppose motivational states "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"A \\subset B \\subset C"}]},{"type":"text","value":"; properties "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"p_1 \\in A, p_2 \\in B/A, p_3 \\in C/B"}]},{"type":"text","value":"; outcomes "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"x \\in p_1, y \\notin p_1, x,y \\in p_2, x \\in p_3, y \\notin p_3"}]},{"type":"text","value":".\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Under 1+2 system, there can exist a player preference family such that "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"x \\preceq_{A} y \\land y \\preceq_{B} x"}]},{"type":"text","value":".\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Under 1+3 system this would not be possible; "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"p_2"}]},{"type":"text","value":" contains both outcomes, which mean it does not distinguish between them. But "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"x \\preceq_{B} y, y \\preceq_{C} x"}]},{"type":"text","value":" is possible, because "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"p_3"}]},{"type":"text","value":" "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"does"}]},{"type":"text","value":" distinguish between the outcomes.\n"}]}]}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"  Two theorems are presented:\n"}]},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"If "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"\\mathcal{M}"}]},{"type":"text","value":" is intersection-closed, an agent's family of preference-orders satisfies 1+2 iff it is \"property-based\".\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"If "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"\\mathcal{M}"}]},{"type":"text","value":" is subset-closed, an agent's family of preference-orders satisfies 1+2 iff it is \"property-based in a separable way\", i.e. the "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"ranking over the powerset of all properties"}]},{"type":"text","value":" exhibits independence of irrelevant alternatives. "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"S_1 \\ge S_2 \\text{ iff } S_1 \\cup T \\ge S_2\\cup T"}]}]}]}]}]}]},{"type":"element","tagName":"h1","properties":{"id":"a-topology-over-properties"},"children":[{"type":"text","value":"A topology over properties"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We have been discussing making the set "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"\\mathcal{M}"}]},{"type":"text","value":" of a player's possible motivational states a topology, in order to use it as an \"organizing principle\" that lets us start engaging with attaching meanings to the properties that have some internal structure. I think I understand some of "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"why"}]},{"type":"text","value":" now: a topology over properties might let us treat the properties as sentences in a language. The semantics of the language ought to follow from its motivating example, and then dictate what the structure even ought to be; but its at least allowing unions and intersections, and having a Top and a Bottom, seem like good starting assumptions.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"mathcal{M}"}]},{"type":"text","value":" being a topology is ensured by axiom 3, and under axiom 2 it's actually a pi-system? Apparently? Which is to say, Wikipedia tells me that this is the name for a  subset of a powerset that is intersection-closed but not union-closed.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The function to output the topological closure (is this valid phrasing?) of a given subset of a powerset is written. What relies on it holding? I remain unsure, and am going to try to approach the problem from the angle of the motivating examples instead of tooling around here without, well, motivation.\n"}]},{"type":"element","tagName":"h1","properties":{"id":"ideas-for-semantics"},"children":[{"type":"text","value":"Ideas for semantics"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Some ideas for the semantics we can assign to this system:\n"}]},{"type":"element","tagName":"h2","properties":{"id":"properties-of-outcomes-as-intentions-"},"children":[{"type":"text","value":"Properties of outcomes as intentions "}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I've been reading G.E.M. Anscombe's "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Intention"}]},{"type":"text","value":", and thoguht of this.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Agents select for outcomes, operating from inside certain contexts. Properties that are derivable by applying DL's theorems can then be a construction of \"what the agent was going for.\"\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"What is the organizing principle of the properties that then tells us the relationship between aim A and aim B? That structure is then the structure of intention.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We can take Anscombe as a first step to understanding how to assign semantics to motivational states, outcomes, and properties respectively; and what structure over properties to begin looking at (and what might follow as a result.)\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Components of organizing principles that suggest themselves, from our understanding so far:\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"epistemics. the motivational states are indications of what agents know about the alternatives. thus, the properties are factual assertions about the outcomes that matter to agents.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"the properties of outcomes can be factual assertions that describe the extensional game further\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"assertions about reachability.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"assertions stronger than reachability\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"conditions that help us answer the question \"given what they did, what did they want?\" (\"can we derive it? can we prove it?\")\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"conditions that help us assert (or, less likely, disprove) that \"given that an agent did that, they must have wanted "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"something"}]},{"type":"text","value":" that is congruent to the structure presented.\" This gives us a falsifiable assertion that I can throw a dataset at.\n"}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"relevance. the motivational states represent the playing-out of a resource bound on reasoning, which we can understand to be true based on how many properties are in each state - which is monotonic to how many outcomes the agent can distinguish between.\n"}]}]}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I will send my summary notes on Anscombe once I have made a fair copy. Their current form is, in several senses, unreadable chicken scratch.\n"}]},{"type":"element","tagName":"h2","properties":{"id":"reasons-why-players-might-move-from-one-motivational-state-to-the-other-"},"children":[{"type":"text","value":"reasons why players might move from one motivational state to the other: "}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The condition kept in mind while generating these: the reasoning must be expressed in terms already defined in the game structure, or derived from them.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The motivstates represent what players know about the outcomes - updating to add a property is adding a fact to the universe of consideration.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The motivstates represent \"relevance\" - updating to add a property necessitates dropping another one, and players optimize for reaching outcomes that would be preferred under a maximal motivstate that they can't actually ever hold.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The motivstates represent information about the game itself:\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Reachability - it would be a simplification of the game tree\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Whether some future game is gluable onto an outcome.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"A fact about "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"the other players"}]},{"type":"text","value":" (what type would that fact have?)\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We are trying to assert that motivstates are things that players can infer about other players. What would they be trying to find out?\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Easy answer: what the other players are going to do. So, a partial strategy? Something of the form \""},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"p \\in M_{Alice}"}]},{"type":"text","value":" iff Alice expects Bob to move left at some point in future play\".\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Another easy answer: what players want. So: \""},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"f(p) \\in M_{Alice}"}]},{"type":"text","value":" iff Alice thinks Bob is ranking some property "},{"type":"element","tagName":"span","properties":{"className":["math","math-inline"]},"children":[{"type":"text","value":"p"}]},{"type":"text","value":" higher than all other properties.\"\n"}]}]}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Verbs - intentions that connect moves to ends, that can be inferred and matched to signalling moves over the course of play.\n"}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"The motivstates represent concerns that are apt to some environmental fact: e.g. the season dictating the parameters for selecting fruit. In monsoon you must look for thick skins, in summer you must look for high water content, etc. Interesting, because it's a way to show that the preference cycle might be entrained by an environmental cycle, and therefore rational in context.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This is called a zeitgeber. "},{"type":"element","tagName":"a","properties":{"href":"https://astralcodexten.substack.com/p/diseasonality?s=r"},"children":[{"type":"text","value":"Diseasonality - by Scott Alexander - Astral Codex Ten"}]},{"type":"text","value":" is where I first head about this; there's a LARGE body of literature attached to the idea of a zeitgeber, and I should read it if and when it seems like a good idea to. Modeling it using a similar kind of intransitivity to what we're playing with here would be pretty cool.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Spitball intuition: size of motivstate tracks how \"tight\" your curves can be on a cycle - shifting sands do not make for fine-grained preferences.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"something something lotka-volterra\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I do need to spend some time studying this magic when I can.\n"}]}]}]}]}]}]}]}]}]}]}]},{"type":"element","tagName":"h3","properties":{"id":"concrete-question-let-properties-be-words-in-the-builder-assistant-game-how-many-rounds-of-play-does-it-take-before-the-epistemic-game-catches-up-to-common-knowledge-of-which-properties-constitute-a-player-ps-motivational-state-"},"children":[{"type":"text","value":"CONCRETE QUESTION: let properties be words in the builder-assistant game. How many rounds of play does it take before the epistemic game catches up to common knowledge of which properties constitute a player p's motivational state? "}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Let there exist a turn based two-player game.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We begin at state R\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"At R, A, and B, one can either\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"play a, which takes one to state A\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"play b, which takes one to state B\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"play s, which takes one to state S, where both players must play either x or y\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"if both players select x or both select y, we go to state WIN; each get one point.\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"else we go back to R.\n"}]}]}]}]}]}]}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This can be extended over some arbitrary alphabet of states-and-moves. Call that alphabet the builder-assistant language.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I think there exist property-based agents who have a winning strategy at this game.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Once we have the collaborative picture, then we can try to break it.\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"can we build a simulation in which siloing happens?\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"I'm defining \"siloing\" as \"several coalitions achieving coordination internally takes fewer steps to reach than the grand coalition achieving coordination.\"\n"}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"can we define a complexity measure according to which a population speaking a language exhibits siloing, or other such effects, past a threshold in that measure?\n"}]},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"My naive first guess for a complexity measure is \"number of tokens in the motivstate.\"\n"}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"My second guess is \"minimum number of steps needed to achieve common knowledge of everybody's motivstate in a coalition.\"\n"}]}]}]}]},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"what is the \"shape\" of the game that exhibits the minimum number of steps needed to achieve common knowledge?\n"}]}]}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"If I recall correctly you have mentioned you and Parkih 2004 as a referent for agents agreeing upon a protocol of further discourse. I will go read that this week.\n"}]},{"type":"element","tagName":"h1","properties":{"id":"the-reason-dl-have-presented-an-axiomatization-is-that-axioms-are-falsifiable-statements-"},"children":[{"type":"text","value":"the reason DL have presented an axiomatization is that axioms are falsifiable statements. "}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"They serve as the condition A in the guarded statement \"if A holds in universe U then model M holds in universe U\".\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"We can check if A holds per falisfiability, and elevate the rest of model M to hold also if it does.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"SO: I ought to find a dataset of preferences to test for the axioms suggested. I will go hunting. Time to strengthen our semiotics.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"This has been last week and part of the ten days preceding, adapted from my notes, the taking of which I've reapplied myself to. I hope I'm on a useful track (or at least a few useful tracks out of the many I seem to be on - convergence seems nigh, but I can't be sure.) Let me know what you think, whether here or in call. Speaking of: is this Friday good for you or would an alternate time be better?\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"See you soon, and I hope to find you well.\n"}]},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Sahiti\n"}]}]},"filetags":{},"backlinks":[]},"__N_SSG":true}